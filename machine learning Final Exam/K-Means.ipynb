{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import csv\n",
    "from sklearn import metrics, cross_validation\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#Returns dictionary of labels; key is label as string, value is a unique index\n",
    "def get_category_labels_as_dict():\n",
    "    category_dict = {}\n",
    "    num_category = 0\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            if not category_dict.has_key(tokens[1]):\n",
    "                category_dict[tokens[1]] = num_category\n",
    "                num_category += 1\n",
    "    return category_dict\n",
    "\n",
    "#Returns labels of training set as an array of strings\n",
    "def get_train_labels():\n",
    "    train_labels = []\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            train_labels.append(tokens[1])\n",
    "    return train_labels\n",
    "\n",
    "#Returns train labels as numpy array, each label is unique index; params: dictionary of label to unique index, array of labels as strings\n",
    "#Usage: get_train_labels_as_unique_indices(get_category_labels_as_dict(), get_train_labels())\n",
    "def get_train_labels_as_unique_indices(label_dictionary, train_label_array):\n",
    "    train_labels_as_index = []\n",
    "    for i in range(len(train_label_array)):\n",
    "        label_name = train_label_array[i]\n",
    "        index = label_dictionary[label_name]\n",
    "        train_labels_as_index.append(index)\n",
    "    return np.array(train_labels_as_index)\n",
    "\n",
    "#Translates index values back into string labels\n",
    "def get_labels_from_indices(label_dictionary, Y_predicted):\n",
    "    labels = []\n",
    "    for i in range(len(Y_predicted)):\n",
    "        target = Y_predicted[i]\n",
    "        for key in label_dictionary.keys():\n",
    "            if label_dictionary[key] == target:\n",
    "                labels.append(key)\n",
    "                break\n",
    "    return labels\n",
    "\n",
    "#Writes the CSV file\n",
    "def print_output(Y_predicted):\n",
    "    with open('./CS5785-final-data/test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    with open('kaggle_submission_vote.csv', \"wb\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['ID', 'Category'])\n",
    "        for index in range(len(Y_predicted)):\n",
    "            writer.writerow([lines[index], Y_predicted[index]])\n",
    " \n",
    "#calculate cross validation score\n",
    "def cross_validation_accuracy(X, Y, folds, model):\n",
    "    average = 0\n",
    "    \n",
    "    for train_indices, test_indices in cross_validation.KFold(len(X), n_folds=folds):\n",
    "    \n",
    "        X_train = X[train_indices]\n",
    "        Y_train = Y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        Y_test = Y[test_indices]\n",
    "\n",
    "        Y_predicted = model.fit(X_train, Y_train).predict(X_test)\n",
    "    \n",
    "        #Compare Y_test and Y_predicted\n",
    "        average += (Y_predicted == Y_test).sum() / float(len(Y_test))\n",
    "        \n",
    "    return average / float(folds)\n",
    "\n",
    "#Returns attributes of train data as numpy array\n",
    "def get_train_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#Returns attributes of test data as numpy array\n",
    "def get_test_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#normalizes the data by normNumber-norm\n",
    "def normalize(X_train, normNumber):\n",
    "    X_train= np.array(X_train)\n",
    "    norm2 = LA.norm(X_train, axis = 0, ord = normNumber)\n",
    "    for i in range(len(X_train)):\n",
    "       X_train[i][0] = X_train[i][0]/norm2[0]\n",
    "       X_train[i][1] = X_train[i][0]/norm2[1]\n",
    "        \n",
    "    return X_train\n",
    "\n",
    "#Returns SIFT attributes of training data as numpy array\n",
    "def get_train_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_train.npy')\n",
    "\n",
    "#Returns SIFT attributes of test data as numpy array\n",
    "def get_test_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_test.npy')\n",
    "\n",
    "#Returns ALEX attributes of train data as numpy array\n",
    "def get_train_ALEX():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_train.npy')\n",
    "\n",
    "#Returns ALEX_10k attributes of train data as numpy array\n",
    "def get_train_ALEX_10k():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_10k.npy')\n",
    "\n",
    "#Returns SIFT_10k attributes of test data as numpy array\n",
    "def get_train_SIFT_10k():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get Y_train\n",
    "category_dictionary = get_category_labels_as_dict()\n",
    "Y_train_text = get_train_labels()\n",
    "Y_train = get_train_labels_as_unique_indices(category_dictionary, Y_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = get_train_SIFT_10k()\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters = 200, max_iter = 10000)\n",
    "kmout = km.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_SIFT = get_train_SIFT()\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train_SIFT, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  83 181 133 181  29 106 199  93 133 133  31 111  59 193 165  62  72\n",
      "  93  36  22 187  62  94 144 181 105 107 107  82  30   5  91 193 108 170\n",
      " 197  62  49  86 151  79 125 147  97  72   5  62 140  72 174  29 107 154\n",
      " 118 142 151 120 154   8  91 188 130 164 193 130  30  97 133 125 140  98\n",
      " 165  29 174 197 193 141 151  97  20  62  86 157 148  20 107 154 149 154\n",
      "  62  72 154 107 154 108 118 140 154  22  97  89 136 178 154  97  30 118\n",
      " 154  82 197 147  83 168  97 151 106  12 107 178  29 118  22 193 133  39\n",
      "  30 133  50 107  80  97  37   7 181 193   3 139  12 153 104  97  31  58\n",
      " 140 197 145 107 154 151 157  50 118 115 154  29  22  99 176 118  83 151\n",
      " 163 164  50 134  30 151 193  43 147  62 193 193  62 167  30 118  50 127\n",
      "  72  18 118 193 118  45  50 118 118 193  37  97 115 176 157  46  58 193\n",
      " 107 192]\n",
      "[195 143  64 157 196 121 177   9  36  79 143  79  29 196  67  59 148  11\n",
      " 115 148 148 116  25 115 157 112 173 145  14 105 116  85  38  16  73  98\n",
      "  29 175  69  51 137 169  19  24   4 177   4 140 147 104  29 149  74 140\n",
      " 175   4  52 195 105 190 170 149  97  84  86  67 169 116  86  12   4 169\n",
      "  49 141  29 177 116  70  22 115   1 177  98 141  29 181  29  34 141  35\n",
      "  17  35   9 195  52  79 150  72 195  72  86  19 191  85 192  59   4 143\n",
      " 190 169 185 105 125 178 139  11 167  77 196  77 192 196 143  65  79 105\n",
      " 137 179  87 198  86 170  24 151 185  14  98  85 112  83 157  29 159 192\n",
      "  98 175 132 179 145 192  24 128  29 196 177 196 178 141  72  25 170  77\n",
      "  85 170  77  69 109  74  72  72 175  59  38  35  29 199  38  29 163 149\n",
      " 195 195 116 115  87 178 146 161  59 175 149  87  24 177 104 178 137  84\n",
      " 175 175 157  29  20 116  59 143  65 169  35 195 116  85  33  49 157  29\n",
      " 143  16 195 141 143  29  12  35 140 140 125 157  11 175 195 195  74  47\n",
      "  80   4 105 196 196 115 175 131 179 181  34 138   9  85  12 195 150 188\n",
      " 175  60  77  79 105  73 157 196 122  98 150 153 143   4  47 157 147 157\n",
      " 115 175 141 121 137 101 113 135 143 143 109  74 136 175  87 195   8 194\n",
      " 148  87  83 184 191  47  34 137  79  97 116  51  19  59 175  86 150 132\n",
      " 177 196 153  72 184  87 104 101 150 121 104 137 141   2 175   8 113 149\n",
      " 195 199 113  65 192 151 109 175 195  22 136 149  19  72  45  19  65 109\n",
      "  64 141 196 151 181   9  69 170 140  29 150 195 184 177 199  49  77 143\n",
      " 175 113 139 175 157  29 101  86 110  46 195 118 157  85 131 119  16  12\n",
      "  70 195  35 116 137 128 191 196 116  52  85  72 195 119 157  47 125 177\n",
      " 175  11  29  37 157 113 148 177 116 157 116  86  29  72 150  85 141   8\n",
      " 177 143  47  77 170 195  77 100 169   2  11 169 148 109 177  16  77 151\n",
      "  70 196  94  11 115  24 138  29  47 166 195 185 139 169  52  47  19 177\n",
      "  33 190 169 195  93  47  72  84 116 119 195 175 148 120  12  74  69  79\n",
      " 117  20  72   4 183  59  72  20  21 173  86 196  86 113 179  38  79  83\n",
      " 101  52 179  84  47  77 188 148  31 157 122 141 195  88 115 199 192 115\n",
      " 195   2  49 196 121 113 157  35 170 141 196  74 104 175 157   9  29 157\n",
      "  24 196 117   4 143 116 195  21  34 191 195 164  74  89 179 171  70  93\n",
      " 149  35 150 184 131 113 180 195 188 109  48  49 170  67 195  16 195  82\n",
      "  35 109 148 150 157  72  70  38 188  83 119 143   9 185  18  69  82  86\n",
      "  48 196 175 104  69 188  77 195  66 196   9 125  11 148 131  35  87 184\n",
      "  74 150 150 140  24 170  83 125  86  17 169 144  72 199  19 177 153  79\n",
      "  86  72  49  61  82 124  22  12 153 143  91 150  85 150  86  52  72 177\n",
      "  47  85 101  74  72 178  72  98 148  67  47 157 143 143 177  29   9  35\n",
      " 148 178 117  13 146  57  99 190  69 177  83  88  12  72  86 175  79  59\n",
      " 116 169 192  24 138  35 144  19   9 143  74  35 157 196 196   9   8 125\n",
      " 105 188  35  69  72  29  11 121  74 137  47 164 119  84 196 157  88 164\n",
      "  98  48 190  59  52  45  79  46 190 177  49  19 195 109  48 175  72 164\n",
      " 141 143 170 143 151 195 177  93  59 195 181 150 185 138  49  16  11  69\n",
      " 192   8 159  59 157 143 105  98 138 157 191 141  79  59 195  29 195 107\n",
      "  29 129  18  67 192  12  72  87 117  25  91 157 175  77  29 136  47  43\n",
      "  11 104 170 175  72  88  11 122 196   9 169 196 149 179  29 115 165 150\n",
      "  48  29 104 196 177 137 191 195  65  29 150 161 136 188  98  34 175  86\n",
      " 175  72  67 105  25 143 125  87 175 175 177 195 107 148  69 136  46 109\n",
      " 143 128  38 116   2 183 170  18 157 157  29  88 190 141 177  16 195 137\n",
      " 113 100  11  85 138 172 157 136 196 147   4  19 105 101 150   4 171 175\n",
      "   9  36  38 135 153 137 195 196  87  49 104  67  72 175 195 191   9 179\n",
      " 170  51 119  16 177 195 109  74 138 177 195  12 109 175  38  52  88 170\n",
      " 177  37 105 199  47 192  72  19  90 114  22 109  18  29 170  79  72 195\n",
      "  91  13 175  49 177 181  68  13 153 125 143 157  74 131 148  29 146  12\n",
      " 119  11 107  85  29 151  86 148  37 171  83 139  69 195  84  86  25  18\n",
      "  98 109  52 112  72 100  14 195  84  91 129  24  78  85  57  61 181  84\n",
      "  21  86 184  72  69 116 143  59  29  36 184 169  86  59 108 101  74  67\n",
      "  29 124   4  15 113 153 170  72 114 190]\n"
     ]
    }
   ],
   "source": [
    "clusterLabels = lr.predict(kmout.cluster_centers_)\n",
    "\n",
    "X_test = get_test_SIFT()\n",
    "testClusterCentre = km.predict(X_test)\n",
    "print clusterLabels\n",
    "print testClusterCentre\n",
    "#predicted = []\n",
    "\n",
    "#for i in range(len(testClusterCentre)):\n",
    "#    predicted.append(clusterLabels[testClusterCentre[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_text = get_labels_from_indices(categories, predicted)\n",
    "print_output(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136  30 118 181 116 107 133 154  72 151 105 104 140 181  97  62  30 140\n",
      "  37 107 133 134 188  62 133 132  50  62  86  72  99 107 147 151  50 105\n",
      " 151   0 154 107 176 127 107 157 133  29 115  27 107 154  29  78 157  29\n",
      " 118 115  29  64 153  62 197 151  30 147  72 107 197  93  80 149  97 140\n",
      "  43 133 118 154 107  22 133 193 140 148 164 127 181 154 134 133  37 154\n",
      " 118  98  31  30 134 132  83  97  12 188 107 132 106  31 107  62 125 134\n",
      " 138  83 154  97 150 140  97  80   8 193  52 151 181 167 165 165  12 151\n",
      " 118  97 125  93 130  30 193 154 107 151 174 147  58 144 133  83 178  30\n",
      " 144 113 148  14  71  80 181 118  29  97 154 193 151 193   8 193  83 118\n",
      " 148 178 118  30 124 132 164 140 154  57 105  11  72  79 181  71   8 118\n",
      " 134  30  97 174  80  45 151 116  19  72  59  83  43 105  29 115  97  98\n",
      " 134  94]\n",
      "[ 30  52 123  30 138  91 164  54  60 158 121  83 192 138 149  81  49  51\n",
      " 105  76  85 102   3 103  30 160 173 139 143  99 102 112 178 143  23 133\n",
      " 156 121 106  45  98 192 189 170 144  54  26 158  90 166 156 156 103 196\n",
      " 115  83  58 145 196  55  35  36 104  81  90  14 192  52 183 184 154 185\n",
      "  81  97 151 151 102  47  96  58   1  10   7  97 156  34  36 103 153 149\n",
      "  36  51 108 145 183 111  51  99 145 112 112 103  61 166 171  81  83 106\n",
      "  18 143 149 182 108 103 112 151  36  51 138  51 171 138 118 103  83 195\n",
      "  98  83  58 164 108  98 162  84 118 155  17 185 160 161  30 192 164  83\n",
      "  88 115  91  41  65  83 162 144 106  30  10 138  44  30 112  84 102 187\n",
      " 112 102  51 151 196  10 112 112 115   8 144 133 192  59  41 106  23 156\n",
      "  30 184 102  51 192  44 112   8  34 144 156   9 162  54   9 176  81 146\n",
      " 185 144  30 192 143 102 116 121  35 192 115 166 102 112 165  98  30 192\n",
      "  52 143 149  97 118 156  85 115 171   1 151  30 151 115 138 184 137 194\n",
      "  99 171 141 138  30  41  69  85  84  34 173  98 183 183 166 145 134 183\n",
      " 121 141   8 171 158  98  30 138 145  88  51  83 138  51 123  30  90 118\n",
      " 188 121  30  49  29  99  84 155 118  85  14  53 138 115  14  97  38 145\n",
      "   9 149  58 121 182  59 103  81  91 198  90  53   8  34 145 185 126  18\n",
      " 183 184 171 156  39   9  68   3 121 139  36  95  28 158 121 190  55  36\n",
      "  18  59  83 190  55  34 119 121 115  96 192 156   8  59  10 197 177 105\n",
      "  79  97 138  84  34 112 183  98 196 184 121  97  76  10 112  54  51  52\n",
      " 139  55  58 144 145 192   3 112 124  84 184 190 145 112 171 177  23 129\n",
      "  47  69  51 102 146  47  83 138 102 143 185 192  30 193  30  99 112 108\n",
      " 144 151 192 141  30 150 143  54 102  30 102 112  36 112  51 112  30  38\n",
      " 183 133  99  51  54 149  51  88 192  13  36 183 187 156 193 176  51 150\n",
      "  47 145  89 151 177  81 137 112  96  79  69  69  58 134   9  53  33  57\n",
      "  14  88 183 184 143 194  58  66  90 193 184 121   9  45 129   8 106  83\n",
      "  98 190  59 143 179  47  59 118  73 155 112  97 112  83  41 178 158 183\n",
      "  99 192  41 152  80  51 183 145 178  30  14  28 145 185  51 108 144 105\n",
      "  30  13 189 138  58  55 134 121  98  97 138 112 166 121  30 123 183  30\n",
      "  81 138 146  91 118 102 145  47  27  28  30  84 193  75  96  56  47 190\n",
      " 192  99  54  49 149   3 177  30 151  95 145  10  10 110  97 143 145 145\n",
      " 115 112   9 121 121  23 146 178 192  52 181  51 112 149  67 151   1 112\n",
      "  18 118 121 165  52 151  91  30  79 138  73  58  11   7  28  51 145  51\n",
      " 193  36  51  91  55  98  99 108 112  36 192 147 112  60 187 112  83  83\n",
      " 143  59  98 173  58 137 123 129  83 118 116  52 112 121 112 143 112 193\n",
      "  45 112 144 193 112  53  95  28 145 145  23 145 121 185  10 151 108 115\n",
      " 190  81   6 185 183  54  85  18 106 151 126 115 129  59 102 121  83  41\n",
      "  90 156  55  84   6  51 108 139  81  52 164 115 134 138 138  35   9   6\n",
      " 196  52 144 106  10 185   9 139  53 152 123 178 140 162 138  30 185  26\n",
      "  17  76  18  41   9  23 158 108  88 151  54   8 184  14 115 121  25  96\n",
      "  28 133  10 118  34 184  54 143  41 145  34 121  76  63  81   3  62  36\n",
      " 171   9 183  54  30 143  36  75 161 134 182  28 158 167  28 192 145 164\n",
      " 192 164 184  97  18   9 183 134 161 150 116 145  99 167 192 192  99 137\n",
      " 178  14  10   3  54 115  36  77 138  54 192 138 192  41 151  41 112 103\n",
      "  18 192 166 138   6  81 182  88   6  36  73 167 138 102 144 178 144 192\n",
      " 144 156 149 182  84 118 197 166 121  18  54  28  65   9  36 138  44 105\n",
      " 185  41  51 183  33 179 102  67 134 138 151 166  18 153 151  99 145  98\n",
      "  55 196 103 112 193 141  30 134 138 164  12 187 166 176 121 144  81  47\n",
      " 108  87 144 155  83 194 118 138   9  54  14 145  59 144  30  28 108  41\n",
      "  98  84 183  80  10 145 192  10  10 108  30 145 156 144 178 112 118 106\n",
      "  54 173  85 112  99  55 189 139  53 105 123 182 133 192 102 145 112 184\n",
      "  23  52 121  81 151 123 140 183 195  54 187 118  35  85  85 151   8 129\n",
      "  23 192  10 112 134  34 151 118 173  45 168 178 151  88 162 164  84  67\n",
      "  85 153  93 194  95 171  53 118  84  74 164  47 112 112  54  18  34 162\n",
      " 139 192 121  10 106  90 185 116 156  23 134 192 143   8 176  12 164  97\n",
      " 151  65 150 141  99 150 102 156 105  18]\n"
     ]
    }
   ],
   "source": [
    "clusterLabels = lr.predict(kmout.cluster_centers_)\n",
    "\n",
    "X_test = get_test_SIFT()\n",
    "testClusterCentre = km.predict(X_test)\n",
    "print clusterLabels\n",
    "print testClusterCentre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345209.871543\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
