{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import csv\n",
    "from sklearn import metrics, cross_validation\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#Returns dictionary of labels; key is label as string, value is a unique index\n",
    "def get_category_labels_as_dict():\n",
    "    category_dict = {}\n",
    "    num_category = 0\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            if not category_dict.has_key(tokens[1]):\n",
    "                category_dict[tokens[1]] = num_category\n",
    "                num_category += 1\n",
    "    return category_dict\n",
    "\n",
    "#Returns labels of training set as an array of strings\n",
    "def get_train_labels():\n",
    "    train_labels = []\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            train_labels.append(tokens[1])\n",
    "    return train_labels\n",
    "\n",
    "#Returns train labels as numpy array, each label is unique index; params: dictionary of label to unique index, array of labels as strings\n",
    "#Usage: get_train_labels_as_unique_indices(get_category_labels_as_dict(), get_train_labels())\n",
    "def get_train_labels_as_unique_indices(label_dictionary, train_label_array):\n",
    "    train_labels_as_index = []\n",
    "    for i in range(len(train_label_array)):\n",
    "        label_name = train_label_array[i]\n",
    "        index = label_dictionary[label_name]\n",
    "        train_labels_as_index.append(index)\n",
    "    return np.array(train_labels_as_index)\n",
    "\n",
    "#Translates index values back into string labels\n",
    "def get_labels_from_indices(label_dictionary, Y_predicted):\n",
    "    labels = []\n",
    "    for i in range(len(Y_predicted)):\n",
    "        target = Y_predicted[i]\n",
    "        for key in label_dictionary.keys():\n",
    "            if label_dictionary[key] == target:\n",
    "                labels.append(key)\n",
    "                break\n",
    "    return labels\n",
    "\n",
    "#Writes the CSV file\n",
    "def print_output(Y_predicted):\n",
    "    with open('./CS5785-final-data/test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    with open('kaggle_submission_vote.csv', \"wb\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['ID', 'Category'])\n",
    "        for index in range(len(Y_predicted)):\n",
    "            writer.writerow([lines[index], Y_predicted[index]])\n",
    " \n",
    "#calculate cross validation score\n",
    "def cross_validation_accuracy(X, Y, folds, model):\n",
    "    average = 0\n",
    "    \n",
    "    for train_indices, test_indices in cross_validation.KFold(len(X), n_folds=folds):\n",
    "    \n",
    "        X_train = X[train_indices]\n",
    "        Y_train = Y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        Y_test = Y[test_indices]\n",
    "\n",
    "        Y_predicted = model.fit(X_train, Y_train).predict(X_test)\n",
    "    \n",
    "        #Compare Y_test and Y_predicted\n",
    "        average += (Y_predicted == Y_test).sum() / float(len(Y_test))\n",
    "        \n",
    "    return average / float(folds)\n",
    "\n",
    "#Returns attributes of train data as numpy array\n",
    "def get_train_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#Returns attributes of test data as numpy array\n",
    "def get_test_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#normalizes the data by normNumber-norm\n",
    "def normalize(X_train, normNumber):\n",
    "    X_train= np.array(X_train)\n",
    "    norm2 = LA.norm(X_train, axis = 0, ord = normNumber)\n",
    "    for i in range(len(X_train)):\n",
    "       X_train[i][0] = X_train[i][0]/norm2[0]\n",
    "       X_train[i][1] = X_train[i][0]/norm2[1]\n",
    "        \n",
    "    return X_train\n",
    "\n",
    "#Returns SIFT attributes of training data as numpy array\n",
    "def get_train_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_train.npy')\n",
    "\n",
    "#Returns SIFT attributes of test data as numpy array\n",
    "def get_test_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_test.npy')\n",
    "\n",
    "#Returns ALEX attributes of train data as numpy array\n",
    "def get_train_ALEX():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_train.npy')\n",
    "\n",
    "def get_test_ALEX():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get Y_train\n",
    "category_dictionary = get_category_labels_as_dict()\n",
    "Y_train_text = get_train_labels()\n",
    "Y_train = get_train_labels_as_unique_indices(category_dictionary, Y_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get X_train and X_test\n",
    "X_train = get_train_attributes()\n",
    "X_test = get_test_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "#Y_predicted_1 = lr.fit(X_train, Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ALEX = get_train_ALEX()\n",
    "X_test_ALEX = get_test_ALEX()\n",
    "#Y_predicted_2 = lr.fit(X_train_ALEX, Y_train).predict(X_test_ALEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_SIFT = get_train_SIFT()\n",
    "X_test_SIFT = get_test_SIFT()\n",
    "#Y_predicted_3 = lr.fit(X_train_SIFT, Y_train).predict(X_test_SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get 3 axes for Y_predicted\n",
    "Y_predicted = []\n",
    "for i in range (0, len(Y_predicted_1)):\n",
    "    vote = []\n",
    "    vote.append(Y_predicted_1[i])\n",
    "    vote.append(Y_predicted_2[i])\n",
    "    vote.append(Y_predicted_3[i])\n",
    "    if(vote.count(vote[1])>=2):\n",
    "        Y_predicted.append(vote[1])\n",
    "    else: Y_predicted.append(vote[0])\n",
    "Y_predicted = np.array(Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Y_predicted to string\n",
    "Y_predicted_text = get_labels_from_indices(category_dictionary, Y_predicted)\n",
    "print_output(Y_predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#models\n",
    "rfc = RandomForestClassifier()\n",
    "lr = linear_model.LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "knnc = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n",
      "0.0903333333333\n",
      "lr\n",
      "0.340333333333\n",
      "gnb\n",
      "0.295666666667\n",
      "bnb\n",
      "0.341333333333\n",
      "knnc\n",
      "0.236333333333\n"
     ]
    }
   ],
   "source": [
    "X_train_ALEX_centered = preprocessing.scale(X_train_ALEX)\n",
    "\n",
    "print \"rfc\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, rfc)\n",
    "print \"lr\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, lr)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, bnb)\n",
    "print \"knnc\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.42435863 -3.46553791 -1.81228862 ..., -1.10022763 -1.89527777\n",
      " -2.52920115]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess X_train_ALEX\n",
    "mean = np.zeros(len(X_train_ALEX[0]))\n",
    "for i in range(len(X_train_ALEX)):\n",
    "    mean += X_train_ALEX[i]\n",
    "mean = mean / float(len(X_train_ALEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ALEX_centered = np.zeros(X_train_ALEX.shape)\n",
    "for i in range(len(X_train_ALEX)):\n",
    "    X_train_ALEX_centered[i,:] = X_train_ALEX[i,:] - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb\n",
      "0.295666666667\n"
     ]
    }
   ],
   "source": [
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n",
      "0.172\n",
      "lr\n",
      "0.261\n",
      "gnb\n",
      "0.165666666667\n",
      "bnb\n",
      "0.249666666667\n",
      "knnc\n",
      "0.171666666667\n"
     ]
    }
   ],
   "source": [
    "print \"rfc\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, rfc)\n",
    "print \"lr\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, lr)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, bnb)\n",
    "print \"knnc\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb\n",
      "0.295666666667\n",
      "bnb\n",
      "0.341333333333\n"
     ]
    }
   ],
   "source": [
    "X_train_ALEX_normalized = normalize(X_train_ALEX, 1)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX_normalized, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX_normalized, Y_train, 3, bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb\n",
      "0.00833333333333\n",
      "bnb\n",
      "0.106\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_normalized = normalize(X_train_SIFT, 2)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalized, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalized, Y_train, 3, bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb\n",
      "0.00866666666667\n",
      "bnb\n",
      "0.106\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_centered = preprocessing.scale(X_train_SIFT)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb\n",
      "0.00833333333333\n",
      "bnb\n",
      "0.106333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_SIFT, Y_train, 3, bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ALEX_centered = preprocessing.scale(X_train_ALEX)\n",
    "X_test_ALEX_centered = preprocessing.scale(X_test_ALEX)\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "predicted = lr.fit(X_train_ALEX_centered, Y_train).predict(X_test_ALEX_centered)\n",
    "\n",
    "predicted_text = get_labels_from_indices(category_dictionary, predicted)\n",
    "print_output(predicted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
