{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import csv\n",
    "from sklearn import metrics, cross_validation\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#Returns dictionary of labels; key is label as string, value is a unique index\n",
    "def get_category_labels_as_dict():\n",
    "    category_dict = {}\n",
    "    num_category = 0\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            if not category_dict.has_key(tokens[1]):\n",
    "                category_dict[tokens[1]] = num_category\n",
    "                num_category += 1\n",
    "    return category_dict\n",
    "\n",
    "#Returns labels of training set as an array of strings\n",
    "def get_train_labels():\n",
    "    train_labels = []\n",
    "    with open('./CS5785-final-data/train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            train_labels.append(tokens[1])\n",
    "    return train_labels\n",
    "\n",
    "#Returns train labels as numpy array, each label is unique index; params: dictionary of label to unique index, array of labels as strings\n",
    "#Usage: get_train_labels_as_unique_indices(get_category_labels_as_dict(), get_train_labels())\n",
    "def get_train_labels_as_unique_indices(label_dictionary, train_label_array):\n",
    "    train_labels_as_index = []\n",
    "    for i in range(len(train_label_array)):\n",
    "        label_name = train_label_array[i]\n",
    "        index = label_dictionary[label_name]\n",
    "        train_labels_as_index.append(index)\n",
    "    return np.array(train_labels_as_index)\n",
    "\n",
    "#Translates index values back into string labels\n",
    "def get_labels_from_indices(label_dictionary, Y_predicted):\n",
    "    labels = []\n",
    "    for i in range(len(Y_predicted)):\n",
    "        target = Y_predicted[i]\n",
    "        for key in label_dictionary.keys():\n",
    "            if label_dictionary[key] == target:\n",
    "                labels.append(key)\n",
    "                break\n",
    "    return labels\n",
    "\n",
    "#Writes the CSV file\n",
    "def print_output(Y_predicted):\n",
    "    with open('./CS5785-final-data/test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    with open('kaggle_submission_vote.csv', \"wb\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['ID', 'Category'])\n",
    "        for index in range(len(Y_predicted)):\n",
    "            writer.writerow([lines[index], Y_predicted[index]])\n",
    " \n",
    "#calculate cross validation score\n",
    "def cross_validation_accuracy(X, Y, folds, model):\n",
    "    average = 0\n",
    "    \n",
    "    for train_indices, test_indices in cross_validation.KFold(len(X), n_folds=folds):\n",
    "    \n",
    "        X_train = X[train_indices]\n",
    "        Y_train = Y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        Y_test = Y[test_indices]\n",
    "\n",
    "        Y_predicted = model.fit(X_train, Y_train).predict(X_test)\n",
    "        #print (Y_predicted == Y_test).sum() / float(len(Y_test))\n",
    "        #Compare Y_test and Y_predicted\n",
    "        average += (Y_predicted == Y_test).sum() / float(len(Y_test))\n",
    "        \n",
    "    return average / float(folds)\n",
    "\n",
    "#Returns attributes of train data as numpy array\n",
    "def get_train_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_train.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#Returns attributes of test data as numpy array\n",
    "def get_test_attributes():\n",
    "    feature_vectors = []\n",
    "    with open('./CS5785-final-data/attributes_test.txt') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(' ')\n",
    "            values = tokens[1].split(',')\n",
    "            fv = []\n",
    "            for value in values:\n",
    "                fv.append(int(value))\n",
    "            feature_vectors.append(fv)\n",
    "    return np.array(feature_vectors)\n",
    "\n",
    "#normalizes the data by normNumber-norm\n",
    "def normalize_column(X_train, normNumber):\n",
    "    X_train= np.array(X_train)\n",
    "    norm2 = LA.norm(X_train, axis = 0, ord = normNumber)\n",
    "    for i in range(len(X_train)):\n",
    "        for j in range(len(X_train[i])):\n",
    "           X_train[i][j] = X_train[i][j]/norm2[j]\n",
    "    return X_train\n",
    "\n",
    "def normalize_row(X_train, normNumber):\n",
    "    X_train= np.array(X_train)\n",
    "    norm2 = LA.norm(X_train, axis = 1, ord = normNumber)\n",
    "    for i in range(len(X_train)):\n",
    "        for j in range(len(X_train[i])):\n",
    "           X_train[i][j] = X_train[i][j]/norm2[i]\n",
    "    return X_train\n",
    "\n",
    "def mean_subtraction(X_train):\n",
    "    mean = np.zeros(len(X_train[0]))\n",
    "    for i in range(len(X_train)):\n",
    "        mean += X_train[i]\n",
    "    mean = mean / float(len(X_train))\n",
    "    \n",
    "    X_train_centered = np.zeros(X_train.shape)\n",
    "    for i in range(len(X_train)):\n",
    "        X_train_centered[i,:] = X_train[i,:] - mean\n",
    "    return X_train_centered\n",
    "\n",
    "#Returns SIFT attributes of training data as numpy array\n",
    "def get_train_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_train.npy')\n",
    "\n",
    "#Returns SIFT attributes of test data as numpy array\n",
    "def get_test_SIFT():\n",
    "    return np.load('./CS5785-final-data/SIFTBoW_test.npy')\n",
    "\n",
    "#Returns ALEX attributes of train data as numpy array\n",
    "def get_train_ALEX():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_train.npy')\n",
    "\n",
    "def get_test_ALEX():\n",
    "    return np.load('./CS5785-final-data/alexnet_feat_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_dictionary = get_category_labels_as_dict()\n",
    "Y_train_text = get_train_labels()\n",
    "Y_train = get_train_labels_as_unique_indices(category_dictionary, Y_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = get_train_attributes()\n",
    "X_test = get_test_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ALEX = get_train_ALEX()\n",
    "X_test_ALEX = get_test_ALEX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_SIFT = get_train_SIFT()\n",
    "X_test_SIFT = get_test_SIFT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ALEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#models\n",
    "rfc = RandomForestClassifier()\n",
    "lr = linear_model.LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "knnc = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, rfc)\n",
    "#print \"lr\"\n",
    "#print cross_validation_accuracy(X_train_ALEX, Y_train, 3, lr)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, bnb)\n",
    "print \"knnc\"\n",
    "print cross_validation_accuracy(X_train_ALEX, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ALEX_centered = mean_subtraction(X_train_ALEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"lr ALEX centered\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"rfc ALEX centered\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, rfc)\n",
    "print \"gnb ALEX centered\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, gnb)\n",
    "print \"bnb ALEX centered\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, bnb)\n",
    "print \"knnc ALEX centered\"\n",
    "print cross_validation_accuracy(X_train_ALEX_centered, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ALEX_standardized = preprocessing.scale(X_train_ALEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"lr ALEX standardized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_standardized, Y_train, 3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc ALEX standardized\n",
      "0.0963333333333\n",
      "gnb ALEX standardized\n",
      "0.295666666667\n",
      "bnb ALEX standardized\n",
      "0.342333333333\n",
      "knnc ALEX standardized\n",
      "0.229\n"
     ]
    }
   ],
   "source": [
    "print \"rfc ALEX standardized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_standardized, Y_train, 3, rfc)\n",
    "print \"gnb ALEX standardized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_standardized, Y_train, 3, gnb)\n",
    "print \"bnb ALEX standardized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_standardized, Y_train, 3, bnb)\n",
    "print \"knnc ALEX standardized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_standardized, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U_ALEX, D_ALEX, VT_ALEX = LA.svd(X_train_ALEX_centered, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vqt_ALEX = VT_ALEX[:1900]\n",
    "#print Vqt_ALEX.shape\n",
    "\n",
    "X_train_ALEX_pca = np.zeros((len(X_train_ALEX_centered), 1900))\n",
    "for i in range(len(X_train_ALEX_centered)):\n",
    "   X_train_ALEX_pca[i,:] = Vqt_ALEX.dot(X_train_ALEX_centered[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc ALEX centered pca\"\n",
    "print cross_validation_accuracy(X_train_ALEX_pca, Y_train, 3, rfc)\n",
    "#print \"lr ALEX centered pca\"\n",
    "#print cross_validation_accuracy(X_train_ALEX_pca, Y_train, 3, lr)\n",
    "print \"gnb ALEX centered pca\"\n",
    "print cross_validation_accuracy(X_train_ALEX_pca, Y_train, 3, gnb)\n",
    "print \"bnb ALEX centered pca\"\n",
    "print cross_validation_accuracy(X_train_ALEX_pca, Y_train, 3, bnb)\n",
    "print \"knnc ALEX centered pca\"\n",
    "print cross_validation_accuracy(X_train_ALEX_pca, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ALEX_row_normalized = normalize_row(X_train_ALEX,1)\n",
    "X_test_ALEX_row_normalized = normalize_row(X_test_ALEX,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dual classifier\n",
    "\n",
    "X_train_ALEX_row_normalized = normalize_row(X_train_ALEX,1)\n",
    "X_test_ALEX_row_normalized = normalize_row(X_test_ALEX,1)\n",
    "\n",
    "predicted_gnb = gnb.fit(X_train_ALEX_row_normalized, Y_train).predict(X_test_ALEX_row_normalized)\n",
    "#append results\n",
    "Y_train_gnb = np.append(Y_train, predicted_gnb)\n",
    "#X_train_ALEX_new = np.append(X_train_ALEX_row_normalized, X_test_ALEX_row_normalized)\n",
    "X_train_ALEX_gnb = np.vstack((X_train_ALEX_row_normalized, X_test_ALEX_row_normalized))\n",
    "print \"bnb ALEX normalized gnb -> bnb\"\n",
    "print cross_validation_accuracy(X_train_ALEX_gnb, Y_train_gnb, 3, bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb ALEX normalized abc\n",
      "0.00666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "print \"abc ALEX normalized\"\n",
    "print cross_validation_accuracy(X_train_ALEX_row_normalized, Y_train, 3, abc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb ALEX normalized gnb -> bnb\n",
      "0.486023117474\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#triple classifier\n",
    "\n",
    "predicted_gnb_bnb = bnb.fit(X_train_ALEX_gnb, Y_train_gnb).predict(X_test_ALEX_row_normalized)\n",
    "#append results\n",
    "Y_train_gnb_bnb = np.append(Y_train_gnb, predicted_gnb_bnb)\n",
    "#X_train_ALEX_new = np.append(X_train_ALEX_row_normalized, X_test_ALEX_row_normalized)\n",
    "X_train_ALEX_gnb_bnb = np.vstack((X_train_ALEX_gnb, X_test_ALEX_row_normalized))\n",
    "\n",
    "\n",
    "print \"bnb ALEX normalized gnb -> bnb -> lr\"\n",
    "print cross_validation_accuracy(X_train_ALEX_gnb, Y_train_gnb, 3, lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb ALEX normalized gnb -> bnb -> lr\n",
      "0.0382573154533\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, rfc)\n",
    "print \"lr\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, lr)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, bnb)\n",
    "print \"mnb\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, bnb)\n",
    "print \"knnc\"\n",
    "print cross_validation_accuracy(X_train, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(20):\n",
    "    knnc = KNeighborsClassifier(n_neighbors=k+1)\n",
    "    print k+1\n",
    "    print cross_validation_accuracy(X_train_ALEX, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_centered = normalize_row(X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc\"\n",
    "print cross_validation_accuracy(X_train_centered, Y_train, 3, rfc)\n",
    "print \"lr\"\n",
    "print cross_validation_accuracy(X_train_centered, Y_train, 3, lr)\n",
    "print \"gnb\"\n",
    "print cross_validation_accuracy(X_train_centered, Y_train, 3, gnb)\n",
    "print \"bnb\"\n",
    "print cross_validation_accuracy(X_train_centered, Y_train, 3, bnb)\n",
    "print \"knnc\"\n",
    "print cross_validation_accuracy(X_train_centered, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_SIFT_centered = mean_subtraction(X_train_SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"lr SIFT centered\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc SIFT centered\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, rfc)\n",
    "print \"gnb SIFT centered\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, gnb)\n",
    "print \"bnb SIFT centered\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, bnb)\n",
    "print \"knnc SIFT centered\"\n",
    "print cross_validation_accuracy(X_train_SIFT_centered, Y_train, 3, knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_SIFT_standardized = preprocessing.scale(X_train_SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"lr SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rfc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, rfc)\n",
    "print \"gnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, gnb)\n",
    "print \"bnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, bnb)\n",
    "print \"knnc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, knnc)\n",
    "print \"mnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_standardized, Y_train, 3, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_SIFT_normalize_row = normalize_row(X_train_SIFT,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc SIFT standardized\n",
      "0.0226666666667\n",
      "gnb SIFT standardized\n",
      "0.0193333333333\n",
      "bnb SIFT standardized\n",
      "0.106333333333\n",
      "knnc SIFT standardized\n",
      "0.0533333333333\n",
      "mnb SIFT standardized\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print \"rfc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, rfc)\n",
    "print \"gnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, gnb)\n",
    "print \"bnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, bnb)\n",
    "print \"knnc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, knnc)\n",
    "print \"mnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc SIFT standardized\n",
      "0.019\n",
      "gnb SIFT standardized\n",
      "0.00833333333333\n",
      "bnb SIFT standardized\n",
      "0.106333333333\n",
      "knnc SIFT standardized\n",
      "0.0713333333333\n",
      "mnb SIFT standardized\n",
      "0.0236666666667\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_normalize_row = normalize_row(X_train_SIFT,2)\n",
    "print \"rfc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, rfc)\n",
    "print \"gnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, gnb)\n",
    "print \"bnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, bnb)\n",
    "print \"knnc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, knnc)\n",
    "print \"mnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_row, Y_train, 3, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc SIFT standardized\n",
      "0.015\n",
      "gnb SIFT standardized\n",
      "0.011\n",
      "bnb SIFT standardized\n",
      "0.106333333333\n",
      "knnc SIFT standardized\n",
      "0.0276666666667\n",
      "mnb SIFT standardized\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_normalize_column = normalize_column(X_train_SIFT,1)\n",
    "\n",
    "print \"rfc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, rfc)\n",
    "print \"gnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, gnb)\n",
    "print \"bnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, bnb)\n",
    "print \"knnc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, knnc)\n",
    "print \"mnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc SIFT standardized\n",
      "0.0173333333333\n",
      "gnb SIFT standardized\n",
      "0.00866666666667\n",
      "bnb SIFT standardized\n",
      "0.106333333333\n",
      "knnc SIFT standardized\n",
      "0.044\n",
      "mnb SIFT standardized\n",
      "0.034\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_normalize_column = normalize_column(X_train_SIFT,2)\n",
    "\n",
    "print \"rfc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, rfc)\n",
    "print \"gnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, gnb)\n",
    "print \"bnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, bnb)\n",
    "print \"knnc SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, knnc)\n",
    "print \"mnb SIFT standardized\"\n",
    "print cross_validation_accuracy(X_train_SIFT_normalize_column, Y_train, 3, mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SuperVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "X_train_super = []\n",
    "X_test_super = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    array = np.append(X_train[i], X_train_ALEX[i])\n",
    "    array = np.append(array, X_train_SIFT[i]) \n",
    "    X_train_super.append(array)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    array = np.append(X_test[i], X_test_ALEX[i])\n",
    "    array = np.append(array, X_test_SIFT[i])\n",
    "    X_test_super.append(array)\n",
    "\n",
    "print len(X_test_super[0])\n",
    "print len(X_train_super[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U_super, D_super, VT_super = LA.svd(X_train_super, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vqt_super = VT_super[:1900]\n",
    "#print Vqt_ALEX.shape\n",
    "\n",
    "X_train_super_pca = np.zeros((len(X_train_super), 1900))\n",
    "for i in range(len(X_train_super)):\n",
    "   X_train_super_pca[i,:] = Vqt_super.dot(X_train_super[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
