{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Question 1.(b)\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "with open('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/train2.csv', 'rb') as csvfile:\n",
    "    csv_file = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    header = csv_file.next()  \n",
    "\n",
    "    train =[]                          \n",
    "    \n",
    "    for row in csv_file:      \n",
    "        train.append(row)             \n",
    "    train = np.array(train)\n",
    "    \n",
    "    print train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender  Class  PriceBracket\n",
      "0       0      0               0\n",
      "               1               0\n",
      "               2               1\n",
      "               3               1\n",
      "        1      0               0\n",
      "               1               1\n",
      "               2               1\n",
      "               3               1\n",
      "        2      0               1\n",
      "               1               1\n",
      "               2               0\n",
      "               3               0\n",
      "1       0      0               0\n",
      "               1               0\n",
      "               2               0\n",
      "               3               0\n",
      "        1      0               0\n",
      "               1               0\n",
      "               2               0\n",
      "               3               0\n",
      "        2      0               0\n",
      "               1               0\n",
      "               2               0\n",
      "               3               0\n",
      "Name: Survival, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def AddBinFare(frame, fare_bracket_size=10, number_of_fares=4):\n",
    "  \"\"\"Bin the ticket fare and add a new column BinFare\"\"\"\n",
    "  frame['BinFare'] = ((frame.Fare//fare_bracket_size)\n",
    "                      .clip_upper(number_of_fares-1)\n",
    "                      # Use class as substitute if no fare was given\n",
    "                      .fillna(3-frame.Pclass)\n",
    "                      .astype(np.int))\n",
    "\n",
    "#in order to analyse the price collumn I need to bin up that data\n",
    "#here are my binning parameters the problem we face is some of the fares are very large\n",
    "#So we can either have a lot of bins with nothing in them or we can just absorb some\n",
    "#information and just say anythng over 30 is just in the last bin so we add a ceiling\n",
    "fare_ceiling = 40\n",
    "fare_bracket_size = 10\n",
    "number_of_fares = fare_ceiling // fare_bracket_size\n",
    "number_of_classes = 3 #There were 1st, 2nd and 3rd classes on board\n",
    "\n",
    "data = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/train2.csv',skipinitialspace=1,index_col=[0])\n",
    "AddBinFare(data,\n",
    "           fare_bracket_size=fare_bracket_size,\n",
    "           number_of_fares=number_of_fares)\n",
    "\n",
    "# This reference table will show we the proportion of survivors as a function of\n",
    "# Gender, class and ticket fare.\n",
    "# I can now find the stats of all the women and men on board\n",
    "index_list=[]\n",
    "survival_list=[]\n",
    "genderNames = ['female','male']\n",
    "for sexIdx in range(2):\n",
    "  for classIdx in range(number_of_classes):\n",
    "    for fareIdx in range(number_of_fares):\n",
    "      index_list += [(sexIdx,classIdx,fareIdx)]\n",
    "      survival_probability = (data.Survived[(data.Sex == genderNames[sexIdx])\n",
    "                                            & (data.Pclass-1==classIdx)\n",
    "                                            & (data.BinFare == fareIdx)]\n",
    "                              .mean())\n",
    "      survival_list += [survival_probability]\n",
    "\n",
    "# Turn into a series and transform probabilities into a binary survive label.\n",
    "survival_index = pd.MultiIndex.from_tuples(index_list,\n",
    "                                           names = ['Gender','Class','PriceBracket'])\n",
    "survival_table = (pd.Series(survival_list,\n",
    "                            index=survival_index, name='Survival')\n",
    "\n",
    "                  # Replace nans with zeros and turn binary by assume <0.5 don't survive.\n",
    "                  .fillna(0) > 0.5).astype(np.int)\n",
    "\n",
    "print survival_table.values\n",
    "\n",
    "# Read the test file\n",
    "test = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/test2.csv',index_col=[0])\n",
    "\n",
    "# Calculate the bin fare\n",
    "AddBinFare(test, fare_bracket_size=fare_bracket_size, number_of_fares=number_of_fares)\n",
    "\n",
    "print test[['Fare','Pclass','BinFare']].head(10)\n",
    "\n",
    "# Add survival table based on looking up the survival value of Sex,Pclass, and BinFare\n",
    "test['Survived'] = (test[['Sex','Pclass','BinFare']]\n",
    "                    .apply(lambda s: survival_table[(s[0]=='male', s[1]-1, s[2])],\n",
    "                           axis=1)\n",
    ")\n",
    "\n",
    "# Output csv's for submission\n",
    "test[['Survived']].to_csv('genderclassmodel-pandas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805836139169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>[0.000184188765155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>[-0.433983991759]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parch</td>\n",
       "      <td>[-0.179509109363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gender</td>\n",
       "      <td>[-2.51086859982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AgeFill</td>\n",
       "      <td>[-0.0377290687176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class_2</td>\n",
       "      <td>[-0.567116890173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class_3</td>\n",
       "      <td>[-1.47205698406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embarked_Q</td>\n",
       "      <td>[-0.0111266228027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>embarked_S</td>\n",
       "      <td>[-0.340622681768]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>binFare_1</td>\n",
       "      <td>[0.431524464703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>binFare_2</td>\n",
       "      <td>[0.62259092311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>binFare_3</td>\n",
       "      <td>[1.09986669044]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>intercept</td>\n",
       "      <td>[1.48887264763]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                    1\n",
       "0   PassengerId  [0.000184188765155]\n",
       "1         SibSp    [-0.433983991759]\n",
       "2         Parch    [-0.179509109363]\n",
       "3        Gender     [-2.51086859982]\n",
       "4       AgeFill   [-0.0377290687176]\n",
       "5       class_2    [-0.567116890173]\n",
       "6       class_3     [-1.47205698406]\n",
       "7    embarked_Q   [-0.0111266228027]\n",
       "8    embarked_S    [-0.340622681768]\n",
       "9     binFare_1     [0.431524464703]\n",
       "10    binFare_2      [0.62259092311]\n",
       "11    binFare_3      [1.09986669044]\n",
       "12    intercept      [1.48887264763]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With Fare Bin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the csv file, and skipping the first row as it's header\n",
    "df = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/train2.csv', header=0)\n",
    "\n",
    "# Adding for binary values of Sex and Port of Embarkment\n",
    "df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int) # females = 0, males = 1\n",
    "#df['Port'] = df['Embarked'].map( {'C': 0, 'Q': 1, 'S':2} ).astype(int) # C = 0, Q = 1, S = 2\n",
    "\n",
    "#Dealing with NA values of ages\n",
    "median_ages = np.zeros((2,3))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df[(df['Gender'] == i) & (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "\n",
    "df['AgeFill'] = df['Age']\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        df.loc[ (df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1),'AgeFill'] = median_ages[i,j]\n",
    "\n",
    "df['AgeIsNull'] = pd.isnull(df.Age).astype(int) #annotate a passenger as 1 if its age was NA beforehand\n",
    "\n",
    "\n",
    "\n",
    "# Converting fares into categorical features ($0-9 = 0,  $10-19 = 1,  $20-29 = 2,  $30-39 = 3) \n",
    "fare_ceiling = 40 #any fare that costs more than or equal to 40 will be put in the highest fare bin - fare bin 3\n",
    "fare_bracket_size = 10\n",
    "number_of_fares = fare_ceiling / fare_bracket_size\n",
    "number_of_classes = 3 \n",
    "df['BinFare'] = ((df.Fare/fare_bracket_size).clip_upper(number_of_fares-1).astype(np.int))\n",
    "\n",
    "# Dealing with categorical features through dummy variables\n",
    "dummy_class = pd.get_dummies(df['Pclass'], prefix='class')\n",
    "dummy_embarked = pd.get_dummies(df['Embarked'], prefix='embarked')\n",
    "dummy_binFare = pd.get_dummies(df['BinFare'], prefix='binFare')\n",
    "\n",
    "cols_to_keep = (df.columns.values)\n",
    "df = df[cols_to_keep].join(dummy_class.ix[:, 'class_2':]).join(dummy_embarked.ix[:, 'embarked_Q':]).join(dummy_binFare.ix[:, 'binFare_1':]) #Join dummy variables for embarked, class and bin fare\n",
    "df['intercept'] = 1.0 #add intercept for categorical features\n",
    "\n",
    "\n",
    "survival = df['Survived'] \n",
    "\n",
    "# Dropping unused features\n",
    "df = df.drop(['Survived','Ticket','Cabin','Name', 'Sex','Pclass', 'Embarked', 'Age', 'Fare', 'AgeIsNull', 'BinFare'], axis=1) #ticket and cabin features have too many NA values. Name has too many categories that cannot be reduced. Sex, Age, Pclass and Embarked are ignored post data cleaning.\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "y = survival\n",
    "model = LogisticRegression()\n",
    "model.fit(df, y)\n",
    "\n",
    "print model.score(df, y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "0.79797979798\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "# Import the csv file, and skipping the first row as it's header\n",
    "train = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/train2.csv', header=0)\n",
    "test = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/test2.csv', header=0)\n",
    "\n",
    "print train.describe()\n",
    "# Adding for binary values of Sex (females = 0, males = 1)\n",
    "train['Sex'] = train['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "test['Sex'] = test['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "\n",
    "#Dealing with NA values of ages \n",
    "median_ages = np.zeros((2,3)) #creating array of median ages for different sex and class\n",
    "#mean_fare = np.zeros((2,3))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = train[(train['Sex'] == i) & (train['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "        #median_fare[i,j] = train[(train['Sex'] == i) & (train['Pclass'] == j+1)]['Fare'].dropna().median()\n",
    "\n",
    "for i in range(0, 2): #filling in the NA values with appropriate values\n",
    "    for j in range(0, 3):\n",
    "        train.loc[ (train.Age.isnull()) & (train.Sex == i) & (train.Pclass == j+1),'Age'] = median_ages[i,j]\n",
    "        test.loc[ (test.Age.isnull()) & (test.Sex == i) & (test.Pclass == j+1),'Age'] = median_ages[i,j]\n",
    "        #train.loc[ (train.Fare.isnull()) & (train.Sex == i) & (train.Pclass == j+1),'Fare'] = median_fare[i,j]\n",
    "        #test.loc[ (test.Fare.isnull()) & (test.Sex == i) & (test.Pclass == j+1),'Fare'] = median_fare[i,j]\n",
    "\n",
    "#Dealing with NA values of fare\n",
    "test.loc[ (test.Fare.isnull()),'Fare'] =  train['Fare'].mean()\n",
    "\n",
    "# Converting fares into categorical features ($0-9 = 0,  $10-19 = 1,  $20-29 = 2,  $30-39 = 3) \n",
    "fare_ceiling = 40 #any fare that costs more than or equal to 40 will be put in the highest fare bin - fare bin 3\n",
    "fare_bracket_size = 10\n",
    "number_of_fares = fare_ceiling / fare_bracket_size\n",
    "number_of_classes = 3 \n",
    "train['BinFare'] = ((train.Fare/fare_bracket_size).clip_upper(number_of_fares-1).astype(np.int))\n",
    "test['BinFare'] = ((test.Fare/fare_bracket_size).clip_upper(number_of_fares-1).astype(np.int))\n",
    "\n",
    "# Dealing with categorical features through dummy variables\n",
    "dummy_class = pd.get_dummies(train['Pclass'], prefix='class')\n",
    "dummy_embarked = pd.get_dummies(train['Embarked'], prefix='embarked')\n",
    "dummy_binFare = pd.get_dummies(train['BinFare'], prefix='binFare')\n",
    "\n",
    "train_cols_to_keep = (train.columns.values)\n",
    "test_cols_to_keep = (test.columns.values)\n",
    "\n",
    "train = train[train_cols_to_keep].join(dummy_class.ix[:, :]).join(dummy_embarked.ix[:, :]).join(dummy_binFare.ix[:, :]) #Join dummy variables for embarked, class and bin fare\n",
    "test = test[test_cols_to_keep].join(dummy_class.ix[:, :]).join(dummy_embarked.ix[:, :]).join(dummy_binFare.ix[:, :])\n",
    "\n",
    "train['intercept'] = 1.0 #add intercept for categorical features\n",
    "test['intercept'] = 1.0 #\n",
    "\n",
    "# Creating target vector for training data\n",
    "y_train = train['Survived'] \n",
    "test['Survived'] = 0\n",
    "y_test = test[ ['PassengerId', 'Survived'] ]\n",
    "\n",
    "# Dropping unused features\n",
    "train = train.drop(['PassengerId','Survived','Ticket','Cabin','Name','Pclass', 'Embarked', 'Fare'], axis=1) #ticket and cabin features have too many NA values. Name has too many categories that cannot be reduced. Sex, Age, Pclass and Embarked are ignored post data cleaning.\n",
    "test = test.drop(['PassengerId','Survived','Ticket','Cabin','Name','Pclass', 'Embarked', 'Fare'], axis=1) #ticket and cabin features have too many NA values. Name has too many categories that cannot be reduced. Sex, Age, Pclass and Embarked are ignored post data cleaning.\n",
    "\n",
    "# Creating Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(train, y_train)\n",
    "\n",
    "# Finding out accuracy via cross validation score for training data\n",
    "scores = cross_validation.cross_val_score(model, train, y_train)\n",
    "print np.mean(scores)\n",
    "\n",
    "#Predicting output of testing data\n",
    "predicted = model.predict(test)\n",
    "y_test['Survived'] = predicted\n",
    "\n",
    "y_test.to_csv('output2.csv', index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# load dataset\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)\n",
    "\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + \\\n",
    "                  religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ec75107b792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Adding for binary values of Embarked (C = 0, Q = 1, S = 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m   2409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2410\u001b[0m         mgr = self._data.astype(\n\u001b[0;32m-> 2411\u001b[0;31m             dtype=dtype, copy=copy, raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[1;32m   2412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m                                                  copy=align_copy)\n\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2459\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[0;32m--> 373\u001b[0;31m                             values=values, **kwargs)\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, raise_on_error, values, klass, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             newb = make_block(values,\n",
      "\u001b[0;32m/Users/chongyeegan/anaconda/lib/python2.7/site-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot convert NA to integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "#Without Categories\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "# Import the csv file, and skipping the first row as it's header\n",
    "train = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/train2.csv', header=0)\n",
    "test = pd.read_csv('/Users/chongyeegan/Documents/Modern Analytics/Homework 1/test2.csv', header=0)\n",
    "\n",
    "# Adding for binary values of Sex (females = 0, males = 1)\n",
    "train['Gender'] = train['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "test['Gender'] = test['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Adding for binary values of Embarked (C = 0, Q = 1, S = 2)\n",
    "train['Embarked'] = train['Embarked'].map( {'C': 0, 'Q': 1, 'S':2} ).astype(int)\n",
    "test['Embarked'] = test['Embarked'].map({'C': 0, 'Q': 1, 'S':2}).astype(int)\n",
    "\n",
    "#Dealing with NA values of ages \n",
    "median_ages = np.zeros((2,3)) #creating array of median ages for different gender and class\n",
    "#mean_fare = np.zeros((2,3))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = train[(train['Gender'] == i) & (train['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "              \n",
    "train['AgeFill'] = train['Age'] #create a new feature for non-NA ages\n",
    "test['AgeFill'] = test['Age']\n",
    "\n",
    "for i in range(0, 2): #filling in the NA values with appropriate values\n",
    "    for j in range(0, 3):\n",
    "        train.loc[ (train.Age.isnull()) & (train.Gender == i) & (train.Pclass == j+1),'AgeFill'] = median_ages[i,j]\n",
    "        test.loc[ (test.Age.isnull()) & (test.Gender == i) & (test.Pclass == j+1),'AgeFill'] = median_ages[i,j]\n",
    "        #train.loc[ (train.Fare.isnull()) & (train.Gender == i) & (train.Pclass == j+1),'FareFill'] = median_fare[i,j]\n",
    "        #test.loc[ (test.Fare.isnull()) & (test.Gender == i) & (test.Pclass == j+1),'FareFill'] = median_fare[i,j]\n",
    "\n",
    "#Dealing with NA values of fare\n",
    "test.loc[ (test.Fare.isnull()),'Fare'] =  train['Fare'].mean()\n",
    "\n",
    "print train.info()\n",
    "\n",
    "#Dealing with NA values of Embark\n",
    "train.loc[ (test.Embarked.isnull()),'Embarked'] =  train['Embarked'].mean()\n",
    "test.loc[ (test.Embarked.isnull()),'Embarked'] =  train['Embarked'].mean()\n",
    "\n",
    "# Creating target vector for training data\n",
    "y_train = train['Survived'] \n",
    "test['Survived'] = 0\n",
    "y_test = test[ ['PassengerId', 'Survived'] ]\n",
    "\n",
    "# Dropping unused features\n",
    "train = train.drop(['PassengerId','Survived','Ticket','Cabin','Name', 'Sex', 'Age'], axis=1) #ticket and cabin features have too many NA values. Name has too many categories that cannot be reduced. Sex, Age, Pclass and Embarked are ignored post data cleaning.\n",
    "test = test.drop(['PassengerId','Survived','Ticket','Cabin','Name', 'Sex', 'Age'], axis=1) #ticket and cabin features have too many NA values. Name has too many categories that cannot be reduced. Sex, Age, Pclass and Embarked are ignored post data cleaning.\n",
    "\n",
    "# Creating Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(train, y_train)\n",
    "\n",
    "# Finding out accuracy via cross validation score for training data\n",
    "scores = cross_validation.cross_val_score(model, train, y_train)\n",
    "print np.mean(scores)\n",
    "\n",
    "# Predicting output of testing data\n",
    "#predicted = model.predict(test)\n",
    "#y_test['Survived'] = predicted\n",
    "\n",
    "#y_test.to_csv('out_logisticRegression.csv', index = False)\n",
    "\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
